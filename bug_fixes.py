"""
Critical Bug Fixes for PyMaris Scientific Image Analyzer
Addresses issues identified in comprehensive debugging report
"""

import os
import struct
import math
from pathlib import Path

class TIFFExportFix:
    """Fix non-standard TIFF export formats for scientific software compatibility"""
    
    @staticmethod
    def export_proper_tiff(labels, filepath):
        """Export segmentation mask as proper TIFF file"""
        try:
            # Try using tifffile library for proper TIFF format
            try:
                import tifffile
                import numpy as np
                
                # Convert labels to numpy array if needed
                if isinstance(labels, list):
                    labels_array = np.array(labels, dtype=np.uint16)
                else:
                    labels_array = labels.astype(np.uint16)
                
                # Write proper TIFF file
                tifffile.imwrite(filepath, labels_array, 
                                metadata={'description': 'PyMaris segmentation mask'})
                return True, "Standard TIFF"
                
            except ImportError:
                # Fallback: Export as ImageJ-compatible text
                TIFFExportFix.export_imagej_text(labels, filepath.replace('.tiff', '.txt'))
                return True, "ImageJ Text"
                
        except Exception as e:
            print(f"TIFF export error: {e}")
            return False, str(e)
    
    @staticmethod
    def export_imagej_text(labels, filepath):
        """Export as ImageJ-compatible text format"""
        with open(filepath, 'w') as f:
            f.write("# ImageJ compatible segmentation mask\n")
            f.write(f"# Width: {len(labels[0]) if labels else 0}\n")
            f.write(f"# Height: {len(labels)}\n")
            f.write("# Import: File > Import > Text Image...\n")
            
            for row in labels:
                f.write('\t'.join(map(str, row)) + '\n')

class MRCExportFix:
    """Fix MRC export format for ChimeraX compatibility"""
    
    @staticmethod
    def export_proper_mrc(volume_data, filepath):
        """Export volume data as proper MRC file"""
        try:
            # Try using mrcfile library
            try:
                import mrcfile
                import numpy as np
                
                if isinstance(volume_data, list):
                    volume_array = np.array(volume_data, dtype=np.float32)
                else:
                    volume_array = volume_data.astype(np.float32)
                
                with mrcfile.new(filepath, overwrite=True) as mrc:
                    mrc.set_data(volume_array)
                    mrc.header.map = mrcfile.constants.MAP_ID
                    mrc.header.machst = mrcfile.utils.machine_stamp()
                    mrc.update_header_from_data()
                    mrc.update_header_stats()
                
                return True, "Standard MRC"
                
            except ImportError:
                # Fallback: Export as raw binary with header
                MRCExportFix.export_raw_volume(volume_data, filepath.replace('.mrc', '.raw'))
                return True, "Raw Binary"
                
        except Exception as e:
            print(f"MRC export error: {e}")
            return False, str(e)
    
    @staticmethod
    def export_raw_volume(volume_data, filepath):
        """Export as raw binary volume with metadata file"""
        try:
            import numpy as np
            
            if isinstance(volume_data, list):
                # Convert nested list to flat array
                flat_data = []
                for slice_2d in volume_data:
                    for row in slice_2d:
                        for pixel in row:
                            flat_data.append(float(pixel))
                volume_array = np.array(flat_data, dtype=np.float32)
                shape = (len(volume_data), len(volume_data[0]), len(volume_data[0][0]))
            else:
                volume_array = volume_data.astype(np.float32)
                shape = volume_array.shape
            
            # Write binary data
            with open(filepath, 'wb') as f:
                volume_array.tobytes()
            
            # Write metadata file
            meta_filepath = filepath.replace('.raw', '_meta.txt')
            with open(meta_filepath, 'w') as f:
                f.write(f"# PyMaris Volume Data\n")
                f.write(f"Dimensions: {' x '.join(map(str, shape))}\n")
                f.write(f"Data type: float32\n")
                f.write(f"Byte order: little-endian\n")
                f.write(f"Import instructions: Use as raw volume in visualization software\n")
                
        except Exception as e:
            print(f"Raw volume export error: {e}")

class ChimeraXPathFix:
    """Fix hardcoded ChimeraX installation paths"""
    
    @staticmethod
    def find_chimerax_installation():
        """Find ChimeraX installation with expanded search"""
        # Common installation paths
        common_paths = [
            # Windows
            r"C:\Program Files\ChimeraX\bin\ChimeraX.exe",
            r"C:\Program Files (x86)\ChimeraX\bin\ChimeraX.exe",
            r"C:\Users\{username}\AppData\Local\ChimeraX\bin\ChimeraX.exe",
            # macOS
            "/Applications/ChimeraX.app/Contents/MacOS/ChimeraX",
            "/usr/local/bin/chimerax",
            # Linux
            "/usr/bin/chimerax",
            "/usr/local/bin/chimerax",
            "/opt/chimerax/bin/chimerax",
            "~/bin/chimerax",
            "~/.local/bin/chimerax"
        ]
        
        # Check environment variable first
        chimera_path = os.environ.get('CHIMERAX_PATH')
        if chimera_path and os.path.exists(chimera_path):
            return chimera_path
        
        # Check common paths
        for path in common_paths:
            expanded_path = os.path.expanduser(path.replace('{username}', os.getlogin() if hasattr(os, 'getlogin') else 'user'))
            if os.path.exists(expanded_path):
                return expanded_path
        
        # Check PATH environment variable
        for path_dir in os.environ.get('PATH', '').split(os.pathsep):
            chimera_exe = os.path.join(path_dir, 'chimerax')
            if os.path.exists(chimera_exe):
                return chimera_exe
            chimera_exe = os.path.join(path_dir, 'ChimeraX.exe')
            if os.path.exists(chimera_exe):
                return chimera_exe
        
        return None
    
    @staticmethod
    def create_config_with_chimerax_path():
        """Create configuration file for ChimeraX path"""
        config_dir = Path("config")
        config_dir.mkdir(exist_ok=True)
        
        config_file = config_dir / "config.json"
        
        import json
        
        default_config = {
            "chimerax_path": "",
            "chimerax_auto_detect": True,
            "export_formats": {
                "tiff_use_library": True,
                "mrc_use_library": True
            },
            "performance": {
                "max_workers": 4,
                "memory_limit_mb": 2048
            }
        }
        
        # Try to detect ChimeraX
        detected_path = ChimeraXPathFix.find_chimerax_installation()
        if detected_path:
            default_config["chimerax_path"] = detected_path
        
        with open(config_file, 'w') as f:
            json.dump(default_config, f, indent=2)
        
        return config_file

class TimelapseLogicFix:
    """Fix inconsistent timelapse logic between app.py and timelapse_processor.py"""
    
    @staticmethod
    def fix_app_track_endpoint():
        """Return proper tracking logic instead of simulation"""
        tracking_code = '''
def track_objects():
    """Track objects over time using real timelapse data"""
    data = request.get_json()
    session_id = data.get('session_id')
    
    if session_id not in analysis_cache:
        return jsonify({'error': 'Invalid session'}), 400
    
    try:
        # Check if we have timelapse data
        session_data = analysis_cache[session_id]
        
        if 'timelapse_data' in session_data:
            # Use real timelapse processor
            from timelapse_processor import TimelapseProcessor
            processor = TimelapseProcessor()
            
            # Process timelapse sequence
            sequence = session_data['timelapse_data']
            tracking_results = processor.track_objects_in_sequence(sequence)
            
            return jsonify({
                'success': True,
                'tracks': tracking_results,
                'num_tracks': len(tracking_results),
                'num_frames': len(sequence)
            })
        else:
            # No timelapse data available
            return jsonify({
                'error': 'No timelapse data available for tracking',
                'suggestion': 'Upload multiple images for time series analysis'
            }), 400
            
    except Exception as e:
        return jsonify({'error': f'Tracking failed: {str(e)}'}), 500
        '''
        return tracking_code

class PhaseCorrelationFix:
    """Fix incomplete phase correlation implementation"""
    
    @staticmethod
    def implement_phase_correlation(image1, image2):
        """Proper phase correlation alignment implementation"""
        try:
            # Try using scipy for FFT-based phase correlation
            try:
                import numpy as np
                from scipy import ndimage
                from scipy.fft import fft2, ifft2, fftshift
                
                # Convert to float
                img1 = np.array(image1, dtype=np.float64)
                img2 = np.array(image2, dtype=np.float64)
                
                # Compute FFTs
                fft1 = fft2(img1)
                fft2 = fft2(img2)
                
                # Cross-power spectrum
                cross_power = (fft1 * np.conj(fft2)) / (np.abs(fft1 * np.conj(fft2)) + 1e-10)
                
                # Inverse FFT to get correlation
                correlation = np.real(ifft2(cross_power))
                correlation = fftshift(correlation)
                
                # Find peak
                peak_y, peak_x = np.unravel_index(np.argmax(correlation), correlation.shape)
                
                # Convert to displacement
                center_y, center_x = np.array(correlation.shape) // 2
                dy = peak_y - center_y
                dx = peak_x - center_x
                
                return dx, dy, np.max(correlation)
                
            except ImportError:
                # Fallback to cross-correlation
                return PhaseCorrelationFix.cross_correlation_fallback(image1, image2)
                
        except Exception as e:
            print(f"Phase correlation error: {e}")
            return 0, 0, 0
    
    @staticmethod
    def cross_correlation_fallback(image1, image2):
        """Fallback cross-correlation implementation"""
        try:
            best_dx, best_dy, best_score = 0, 0, 0
            search_range = 20  # Limit search for performance
            
            height1, width1 = len(image1), len(image1[0])
            height2, width2 = len(image2), len(image2[0])
            
            for dy in range(-search_range, search_range + 1):
                for dx in range(-search_range, search_range + 1):
                    score = 0
                    count = 0
                    
                    for y in range(max(0, dy), min(height1, height2 + dy)):
                        for x in range(max(0, dx), min(width1, width2 + dx)):
                            y1, x1 = y, x
                            y2, x2 = y - dy, x - dx
                            
                            if (0 <= y2 < height2 and 0 <= x2 < width2):
                                score += image1[y1][x1] * image2[y2][x2]
                                count += 1
                    
                    if count > 0:
                        normalized_score = score / count
                        if normalized_score > best_score:
                            best_score = normalized_score
                            best_dx, best_dy = dx, dy
            
            return best_dx, best_dy, best_score
            
        except Exception as e:
            print(f"Cross-correlation fallback error: {e}")
            return 0, 0, 0

class DependencyFallbackFix:
    """Fix missing dependency fallbacks in utilities"""
    
    @staticmethod
    def create_analysis_utils_with_fallbacks():
        """Create analysis_utils.py with proper fallbacks"""
        utils_code = '''
"""
Analysis Utilities with Dependency Fallbacks
Provides scientific analysis functions with pure Python fallbacks
"""

# Check for optional dependencies
try:
    import numpy as np
    HAS_NUMPY = True
except ImportError:
    HAS_NUMPY = False
    np = None

try:
    import scipy
    from scipy import ndimage, stats
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False
    scipy = None

try:
    import pandas as pd
    HAS_PANDAS = True
except ImportError:
    HAS_PANDAS = False
    pd = None

try:
    from skimage import filters, measure, segmentation
    HAS_SKIMAGE = True
except ImportError:
    HAS_SKIMAGE = False

def calculate_statistics(data):
    """Calculate basic statistics with fallbacks"""
    if HAS_NUMPY and isinstance(data, np.ndarray):
        return {
            'mean': float(np.mean(data)),
            'std': float(np.std(data)),
            'min': float(np.min(data)),
            'max': float(np.max(data))
        }
    else:
        # Pure Python fallback
        flat_data = []
        if isinstance(data, list):
            for row in data:
                if isinstance(row, list):
                    flat_data.extend(row)
                else:
                    flat_data.append(row)
        else:
            flat_data = list(data)
        
        if not flat_data:
            return {'mean': 0, 'std': 0, 'min': 0, 'max': 0}
        
        mean_val = sum(flat_data) / len(flat_data)
        variance = sum((x - mean_val) ** 2 for x in flat_data) / len(flat_data)
        std_val = variance ** 0.5
        
        return {
            'mean': mean_val,
            'std': std_val,
            'min': min(flat_data),
            'max': max(flat_data)
        }

def correlation_coefficient(x, y):
    """Calculate correlation coefficient with fallbacks"""
    if HAS_SCIPY:
        from scipy.stats import pearsonr
        corr, _ = pearsonr(x, y)
        return corr
    else:
        # Pure Python implementation
        if len(x) != len(y) or len(x) == 0:
            return 0
        
        mean_x = sum(x) / len(x)
        mean_y = sum(y) / len(y)
        
        numerator = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(len(x)))
        sum_sq_x = sum((x[i] - mean_x) ** 2 for i in range(len(x)))
        sum_sq_y = sum((y[i] - mean_y) ** 2 for i in range(len(y)))
        
        denominator = (sum_sq_x * sum_sq_y) ** 0.5
        
        if denominator == 0:
            return 0
        
        return numerator / denominator

def create_dataframe(data):
    """Create DataFrame or return list based on pandas availability"""
    if HAS_PANDAS:
        return pd.DataFrame(data)
    else:
        return data

def gaussian_filter(image, sigma):
    """Apply Gaussian filter with fallbacks"""
    if HAS_SCIPY:
        return ndimage.gaussian_filter(image, sigma)
    else:
        # Simple blur fallback
        return simple_blur(image, int(sigma))

def simple_blur(image, radius):
    """Simple blur implementation"""
    try:
        height = len(image)
        width = len(image[0]) if height > 0 else 0
        
        blurred = [[0 for _ in range(width)] for _ in range(height)]
        
        for y in range(height):
            for x in range(width):
                total = 0
                count = 0
                
                for dy in range(-radius, radius + 1):
                    for dx in range(-radius, radius + 1):
                        ny, nx = y + dy, x + dx
                        if 0 <= ny < height and 0 <= nx < width:
                            total += image[ny][nx]
                            count += 1
                
                blurred[y][x] = total / count if count > 0 else 0
        
        return blurred
        
    except Exception as e:
        print(f"Blur error: {e}")
        return image
        '''
        
        return utils_code

def apply_all_fixes():
    """Apply all critical bug fixes"""
    fixes_applied = []
    
    try:
        # Create config directory and ChimeraX configuration
        config_file = ChimeraXPathFix.create_config_with_chimerax_path()
        fixes_applied.append(f"Created configuration file: {config_file}")
        
        # Create proper analysis utilities
        utils_dir = Path("utils")
        utils_dir.mkdir(exist_ok=True)
        
        utils_file = utils_dir / "analysis_utils.py"
        with open(utils_file, 'w') as f:
            f.write(DependencyFallbackFix.create_analysis_utils_with_fallbacks())
        fixes_applied.append(f"Created analysis utilities with fallbacks: {utils_file}")
        
        # Create updated requirements.txt
        req_file = Path("requirements_fixed.txt")
        with open(req_file, 'w') as f:
            f.write("""# PyMaris Scientific Image Analyzer - Fixed Requirements

# CORE DEPENDENCIES (Required for basic functionality)
# None - Application works with pure Python fallbacks

# OPTIONAL SCIENTIFIC COMPUTING
# Install for enhanced analysis capabilities
numpy>=1.21.0
scipy>=1.7.0
scikit-image>=0.18.0
matplotlib>=3.5.0

# OPTIONAL IMAGE I/O
# Install for comprehensive file format support
tifffile>=2021.0.0  # For proper TIFF export
mrcfile>=1.3.0      # For proper MRC export (ChimeraX compatibility)
imageio>=2.9.0
Pillow>=8.0.0
opencv-python>=4.5.0

# OPTIONAL WEB FRAMEWORK
# Flask-based interface (alternative to built-in server)
flask>=2.0.0
werkzeug>=2.0.0

# OPTIONAL DATA ANALYSIS
pandas>=1.3.0

# NAPARI DESKTOP VERSION (Optional)
# Full desktop application with plugin ecosystem
napari[all]>=0.4.15
magicgui>=0.5.0
qtpy

# MICROSCOPY FILE FORMATS (Optional)
aicsimageio>=4.0.0
readlif>=0.6.0
pylibczirw>=3.0.0
czifile>=2019.0.0
nd2reader>=3.2.0

# AI/ML FEATURES (Optional)
cellpose>=2.0.0
stardist>=0.8.0
btrack>=0.4.0

# DEVELOPMENT TOOLS (Optional)
pytest>=6.0.0
black>=21.0.0
flake8>=3.9.0""")
        fixes_applied.append(f"Created fixed requirements file: {req_file}")
        
        return fixes_applied
        
    except Exception as e:
        return [f"Error applying fixes: {e}"]

if __name__ == "__main__":
    print("Applying critical bug fixes...")
    results = apply_all_fixes()
    for result in results:
        print(f"✓ {result}")
    print("Bug fixes completed!")